A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/Users/user/Documents/coding/NER_by_Mary/src/main.py", line 3, in <module>
    from core.mountains_ner import MountainsNER
  File "/Users/user/Documents/coding/NER_by_Mary/src/core/mountains_ner.py", line 7, in <module>
    import torch
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/__init__.py", line 1477, in <module>
    from .functional import *  # noqa: F403
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/functional.py", line 9, in <module>
    import torch.nn.functional as F
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
    from .transformer import TransformerEncoder, TransformerDecoder, \
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)
  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-01-11 22:05:18.618 | INFO     | core.mountains_ner:get_dataset:29 - DatasetDict({
    train: Dataset({
        features: ['sentence', 'tokens', 'labels'],
        num_rows: 3827
    })
    val: Dataset({
        features: ['sentence', 'tokens', 'labels'],
        num_rows: 478
    })
    test: Dataset({
        features: ['sentence', 'tokens', 'labels'],
        num_rows: 479
    })
})
Some weights of BertForTokenClassification were not initialized from the model checkpoint at Gepe55o/mountain-ner-bert-base and are newly initialized because the shapes did not match:
- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(

  0%|          | 0/360 [00:00<?, ?it/s]  0%|          | 1/360 [03:43<22:16:11, 223.32s/it]  1%|          | 2/360 [06:55<20:24:04, 205.15s/it]  1%|          | 3/360 [09:29<17:59:48, 181.48s/it]  1%|          | 4/360 [11:58<16:41:36, 168.81s/it]  1%|â–         | 5/360 [14:20<15:41:47, 159.18s/it]  2%|â–         | 6/360 [33:57<49:40:51, 505.23s/it]  2%|â–         | 7/360 [37:53<40:53:44, 417.07s/it]  2%|â–         | 8/360 [41:57<35:24:24, 362.12s/it]  2%|â–Ž         | 9/360 [46:18<32:12:49, 330.40s/it]  3%|â–Ž         | 10/360 [49:18<27:36:18, 283.94s/it]  3%|â–Ž         | 11/360 [52:20<24:31:35, 253.00s/it]  3%|â–Ž         | 12/360 [55:25<22:25:50, 232.04s/it]  4%|â–Ž         | 13/360 [58:37<21:12:37, 220.05s/it]  4%|â–         | 14/360 [1:02:07<20:51:43, 217.06s/it]  4%|â–         | 15/360 [1:05:38<20:37:42, 215.25s/it]  4%|â–         | 16/360 [1:09:23<20:51:10, 218.23s/it]  5%|â–         | 17/360 [1:15:12<24:31:55, 257.48s/it]  5%|â–Œ         | 18/360 [1:18:16<22:22:01, 235.44s/it]  5%|â–Œ         | 19/360 [1:20:53<20:04:29, 211.93s/it]  6%|â–Œ         | 20/360 [1:23:30<18:26:09, 195.21s/it]  6%|â–Œ         | 21/360 [1:31:43<26:49:14, 284.82s/it]  6%|â–Œ         | 22/360 [1:36:23<26:36:14, 283.36s/it]  6%|â–‹         | 23/360 [1:39:26<23:41:49, 253.14s/it]  7%|â–‹         | 24/360 [1:42:01<20:51:51, 223.54s/it]  7%|â–‹         | 25/360 [1:46:14<21:37:37, 232.41s/it]  7%|â–‹         | 26/360 [1:50:44<22:37:14, 243.82s/it]  8%|â–Š         | 27/360 [1:54:00<21:13:23, 229.44s/it]  8%|â–Š         | 28/360 [1:59:41<24:15:17, 263.00s/it]  8%|â–Š         | 29/360 [2:05:08<25:56:55, 282.22s/it]  8%|â–Š         | 30/360 [2:09:47<25:46:35, 281.20s/it]  9%|â–Š         | 31/360 [2:13:47<24:34:34, 268.92s/it]  9%|â–‰         | 32/360 [2:17:43<23:35:10, 258.87s/it]  9%|â–‰         | 33/360 [2:22:46<24:44:00, 272.30s/it]  9%|â–‰         | 34/360 [2:26:01<22:33:05, 249.04s/it] 10%|â–‰         | 35/360 [2:29:40<21:40:21, 240.07s/it] 10%|â–ˆ         | 36/360 [2:34:09<22:22:16, 248.57s/it] 10%|â–ˆ         | 37/360 [2:37:18<20:41:33, 230.63s/it] 11%|â–ˆ         | 38/360 [2:41:36<21:22:06, 238.90s/it] 11%|â–ˆ         | 39/360 [2:44:25<19:25:44, 217.89s/it] 11%|â–ˆ         | 40/360 [2:47:33<18:34:28, 208.96s/it] 11%|â–ˆâ–        | 41/360 [2:51:01<18:29:10, 208.62s/it] 12%|â–ˆâ–        | 42/360 [2:55:33<20:06:54, 227.72s/it] 12%|â–ˆâ–        | 43/360 [2:59:38<20:30:47, 232.96s/it] 12%|â–ˆâ–        | 44/360 [3:02:43<19:11:50, 218.71s/it] 12%|â–ˆâ–Ž        | 45/360 [3:05:28<17:42:11, 202.32s/it] 13%|â–ˆâ–Ž        | 46/360 [3:09:55<19:21:48, 222.00s/it] 13%|â–ˆâ–Ž        | 47/360 [3:13:34<19:13:14, 221.07s/it] 13%|â–ˆâ–Ž        | 48/360 [3:17:22<19:19:17, 222.94s/it] 14%|â–ˆâ–Ž        | 49/360 [3:21:42<20:13:20, 234.09s/it] 14%|â–ˆâ–        | 50/360 [3:25:09<19:27:29, 225.97s/it] 14%|â–ˆâ–        | 51/360 [3:28:43<19:05:59, 222.52s/it] 14%|â–ˆâ–        | 52/360 [3:33:24<20:31:51, 239.97s/it] 15%|â–ˆâ–        | 53/360 [3:37:20<20:22:31, 238.93s/it] 15%|â–ˆâ–Œ        | 54/360 [3:39:54<18:07:51, 213.30s/it] 15%|â–ˆâ–Œ        | 55/360 [3:42:23<16:26:04, 193.98s/it] 16%|â–ˆâ–Œ        | 56/360 [3:44:44<15:02:40, 178.16s/it] 16%|â–ˆâ–Œ        | 57/360 [3:47:15<14:18:37, 170.02s/it] 16%|â–ˆâ–Œ        | 58/360 [3:49:52<13:55:14, 165.94s/it] 16%|â–ˆâ–‹        | 59/360 [3:52:30<13:41:16, 163.71s/it] 17%|â–ˆâ–‹        | 60/360 [3:55:00<13:17:10, 159.44s/it] 17%|â–ˆâ–‹        | 61/360 [3:57:35<13:08:23, 158.20s/it] 17%|â–ˆâ–‹        | 62/360 [4:00:11<13:02:51, 157.62s/it] 18%|â–ˆâ–Š        | 63/360 [12:26:48<761:25:19, 9229.36s/it] 18%|â–ˆâ–Š        | 64/360 [12:29:39<535:25:40, 6511.96s/it] 18%|â–ˆâ–Š        | 65/360 [12:34:24<380:32:41, 4643.94s/it] 18%|â–ˆâ–Š        | 66/360 [12:38:08<270:57:47, 3317.92s/it] 19%|â–ˆâ–Š        | 67/360 [12:43:53<197:26:47, 2425.96s/it] 19%|â–ˆâ–‰        | 68/360 [12:50:13<146:59:36, 1812.25s/it] 19%|â–ˆâ–‰        | 69/360 [12:54:28<108:43:42, 1345.10s/it] 19%|â–ˆâ–‰        | 70/360 [12:57:43<80:33:12, 999.97s/it]   20%|â–ˆâ–‰        | 71/360 [13:02:04<62:28:09, 778.16s/it] 20%|â–ˆâ–ˆ        | 72/360 [13:07:26<51:19:18, 641.52s/it] 20%|â–ˆâ–ˆ        | 73/360 [13:10:48<40:36:54, 509.46s/it] 21%|â–ˆâ–ˆ        | 74/360 [13:14:05<33:01:20, 415.67s/it] 21%|â–ˆâ–ˆ        | 75/360 [13:17:18<27:38:28, 349.15s/it] 21%|â–ˆâ–ˆ        | 76/360 [13:21:46<25:36:57, 324.71s/it] 21%|â–ˆâ–ˆâ–       | 77/360 [13:26:05<23:57:51, 304.84s/it] 22%|â–ˆâ–ˆâ–       | 78/360 [13:29:36<21:40:37, 276.73s/it] 22%|â–ˆâ–ˆâ–       | 79/360 [13:33:55<21:11:00, 271.39s/it] 22%|â–ˆâ–ˆâ–       | 80/360 [13:39:05<22:01:31, 283.19s/it] 22%|â–ˆâ–ˆâ–Ž       | 81/360 [13:43:41<21:46:49, 281.04s/it] 23%|â–ˆâ–ˆâ–Ž       | 82/360 [13:47:45<20:49:26, 269.66s/it] 23%|â–ˆâ–ˆâ–Ž       | 83/360 [13:51:57<20:20:55, 264.46s/it] 23%|â–ˆâ–ˆâ–Ž       | 84/360 [13:55:14<18:43:26, 244.23s/it] 24%|â–ˆâ–ˆâ–Ž       | 85/360 [13:57:48<16:34:47, 217.05s/it] 24%|â–ˆâ–ˆâ–       | 86/360 [14:01:31<16:39:45, 218.93s/it] 24%|â–ˆâ–ˆâ–       | 87/360 [14:04:56<16:16:40, 214.66s/it] 24%|â–ˆâ–ˆâ–       | 88/360 [14:07:30<14:50:45, 196.49s/it] 25%|â–ˆâ–ˆâ–       | 89/360 [14:10:00<13:44:42, 182.59s/it] 25%|â–ˆâ–ˆâ–Œ       | 90/360 [14:12:42<13:14:33, 176.57s/it] 25%|â–ˆâ–ˆâ–Œ       | 91/360 [14:16:01<13:40:51, 183.09s/it] 26%|â–ˆâ–ˆâ–Œ       | 92/360 [14:18:57<13:28:22, 180.98s/it] 26%|â–ˆâ–ˆâ–Œ       | 93/360 [14:21:30<12:48:13, 172.63s/it] 26%|â–ˆâ–ˆâ–Œ       | 94/360 [14:23:58<12:12:25, 165.21s/it] 26%|â–ˆâ–ˆâ–‹       | 95/360 [14:27:00<12:32:37, 170.41s/it] 27%|â–ˆâ–ˆâ–‹       | 96/360 [14:29:33<12:05:59, 165.00s/it] 27%|â–ˆâ–ˆâ–‹       | 97/360 [14:32:07<11:49:19, 161.82s/it] 27%|â–ˆâ–ˆâ–‹       | 98/360 [14:34:45<11:40:56, 160.52s/it] 28%|â–ˆâ–ˆâ–Š       | 99/360 [15:08:28<52:08:47, 719.26s/it] 28%|â–ˆâ–ˆâ–Š       | 100/360 [15:12:49<42:02:01, 582.01s/it] 28%|â–ˆâ–ˆâ–Š       | 101/360 [15:16:51<34:31:20, 479.85s/it] 28%|â–ˆâ–ˆâ–Š       | 102/360 [15:20:28<28:44:56, 401.15s/it] 29%|â–ˆâ–ˆâ–Š       | 103/360 [15:23:53<24:25:33, 342.15s/it] 29%|â–ˆâ–ˆâ–‰       | 104/360 [15:28:48<23:19:49, 328.08s/it] 29%|â–ˆâ–ˆâ–‰       | 105/360 [15:33:00<21:37:23, 305.27s/it] 29%|â–ˆâ–ˆâ–‰       | 106/360 [15:37:21<20:36:02, 291.98s/it] 30%|â–ˆâ–ˆâ–‰       | 107/360 [15:58:19<40:52:38, 581.66s/it] 30%|â–ˆâ–ˆâ–ˆ       | 108/360 [16:02:16<33:28:48, 478.29s/it] 30%|â–ˆâ–ˆâ–ˆ       | 109/360 [16:06:20<28:27:37, 408.20s/it] 31%|â–ˆâ–ˆâ–ˆ       | 110/360 [16:42:51<65:28:44, 942.90s/it] 31%|â–ˆâ–ˆâ–ˆ       | 111/360 [18:00:12<141:57:19, 2052.37s/it] 31%|â–ˆâ–ˆâ–ˆ       | 112/360 [18:04:16<104:00:16, 1509.74s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 113/360 [18:08:40<77:56:40, 1136.03s/it]  32%|â–ˆâ–ˆâ–ˆâ–      | 114/360 [18:13:07<59:49:03, 875.38s/it]  32%|â–ˆâ–ˆâ–ˆâ–      | 115/360 [18:34:28<67:51:43, 997.16s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 116/360 [19:24:45<108:39:15, 1603.10s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 117/360 [19:28:23<80:10:02, 1187.67s/it]  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 118/360 [19:32:16<60:35:10, 901.28s/it]  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 119/360 [19:36:04<46:48:04, 699.10s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 120/360 [19:38:26<35:28:36, 532.15s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [2:06:09<6:18:29, 3784.90s/it][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [4:23:06<7:49:16, 5631.29s/it][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [4:24:56<3:58:05, 3571.25s/it][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [4:26:47<1:58:24, 2368.13s/it][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [4:28:07<53:37, 1608.91s/it]  [A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [4:29:26<18:36, 1116.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [4:29:58<00:00, 775.24s/it] [ATraceback (most recent call last):
  File "/Users/user/Documents/coding/NER_by_Mary/src/main.py", line 11, in <module>
    run(main())
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/coding/NER_by_Mary/src/main.py", line 7, in main
    return await MountainsNER().running()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/coding/NER_by_Mary/src/core/mountains_ner.py", line 218, in running
    await self.compute_similarity_and_rank()
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/coding/NER_by_Mary/src/core/mountains_ner.py", line 119, in fine_tune_model
    
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/transformers/trainer.py", line 2618, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/transformers/trainer.py", line 3049, in _maybe_log_save_evaluate
    metrics = self._evaluate(trial, ignore_keys_for_eval)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/transformers/trainer.py", line 3003, in _evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/transformers/trainer.py", line 4050, in evaluate
    output = eval_loop(
             ^^^^^^^^^^
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/transformers/trainer.py", line 4310, in evaluation_loop
    all_losses = all_losses.get_arrays()
                 ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py", line 346, in get_arrays
    self.to_cpu_and_numpy()
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py", line 333, in to_cpu_and_numpy
    new_arrays = nested_numpify(self.tensors)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py", line 180, in nested_numpify
    return t.numpy()
           ^^^^^^^^^
RuntimeError: Numpy is not available
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 120/360 [24:27:48<48:55:37, 733.91s/it]

                                                [A