A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/Users/user/Documents/coding/NER_by_Mary/src/main.py", line 3, in <module>
    from core.mountains_ner import MountainsNER
  File "/Users/user/Documents/coding/NER_by_Mary/src/core/mountains_ner.py", line 7, in <module>
    import torch
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/__init__.py", line 1477, in <module>
    from .functional import *  # noqa: F403
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/functional.py", line 9, in <module>
    import torch.nn.functional as F
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
    from .transformer import TransformerEncoder, TransformerDecoder, \
  File "/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)
  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-01-11 22:05:18.618 | INFO     | core.mountains_ner:get_dataset:29 - DatasetDict({
    train: Dataset({
        features: ['sentence', 'tokens', 'labels'],
        num_rows: 3827
    })
    val: Dataset({
        features: ['sentence', 'tokens', 'labels'],
        num_rows: 478
    })
    test: Dataset({
        features: ['sentence', 'tokens', 'labels'],
        num_rows: 479
    })
})
Some weights of BertForTokenClassification were not initialized from the model checkpoint at Gepe55o/mountain-ner-bert-base and are newly initialized because the shapes did not match:
- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/Users/user/Documents/coding/NER_by_Mary/venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(

  0%|          | 0/360 [00:00<?, ?it/s]  0%|          | 1/360 [03:43<22:16:11, 223.32s/it]  1%|          | 2/360 [06:55<20:24:04, 205.15s/it]  1%|          | 3/360 [09:29<17:59:48, 181.48s/it]  1%|          | 4/360 [11:58<16:41:36, 168.81s/it]  1%|â–         | 5/360 [14:20<15:41:47, 159.18s/it]  2%|â–         | 6/360 [33:57<49:40:51, 505.23s/it]  2%|â–         | 7/360 [37:53<40:53:44, 417.07s/it]  2%|â–         | 8/360 [41:57<35:24:24, 362.12s/it]  2%|â–Ž         | 9/360 [46:18<32:12:49, 330.40s/it]  3%|â–Ž         | 10/360 [49:18<27:36:18, 283.94s/it]  3%|â–Ž         | 11/360 [52:20<24:31:35, 253.00s/it]  3%|â–Ž         | 12/360 [55:25<22:25:50, 232.04s/it]  4%|â–Ž         | 13/360 [58:37<21:12:37, 220.05s/it]  4%|â–         | 14/360 [1:02:07<20:51:43, 217.06s/it]  4%|â–         | 15/360 [1:05:38<20:37:42, 215.25s/it]  4%|â–         | 16/360 [1:09:23<20:51:10, 218.23s/it]  5%|â–         | 17/360 [1:15:12<24:31:55, 257.48s/it]  5%|â–Œ         | 18/360 [1:18:16<22:22:01, 235.44s/it]  5%|â–Œ         | 19/360 [1:20:53<20:04:29, 211.93s/it]  6%|â–Œ         | 20/360 [1:23:30<18:26:09, 195.21s/it]  6%|â–Œ         | 21/360 [1:31:43<26:49:14, 284.82s/it]  6%|â–Œ         | 22/360 [1:36:23<26:36:14, 283.36s/it]  6%|â–‹         | 23/360 [1:39:26<23:41:49, 253.14s/it]  7%|â–‹         | 24/360 [1:42:01<20:51:51, 223.54s/it]  7%|â–‹         | 25/360 [1:46:14<21:37:37, 232.41s/it]  7%|â–‹         | 26/360 [1:50:44<22:37:14, 243.82s/it]  8%|â–Š         | 27/360 [1:54:00<21:13:23, 229.44s/it]  8%|â–Š         | 28/360 [1:59:41<24:15:17, 263.00s/it]  8%|â–Š         | 29/360 [2:05:08<25:56:55, 282.22s/it]  8%|â–Š         | 30/360 [2:09:47<25:46:35, 281.20s/it]  9%|â–Š         | 31/360 [2:13:47<24:34:34, 268.92s/it]  9%|â–‰         | 32/360 [2:17:43<23:35:10, 258.87s/it]  9%|â–‰         | 33/360 [2:22:46<24:44:00, 272.30s/it]  9%|â–‰         | 34/360 [2:26:01<22:33:05, 249.04s/it] 10%|â–‰         | 35/360 [2:29:40<21:40:21, 240.07s/it]